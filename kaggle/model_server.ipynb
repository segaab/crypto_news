{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers torch fastapi uvicorn pydantic python-multipart\n",
    "!pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import uvicorn\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "from typing import Optional\n",
    "import time\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI(title=\"Financial News Analyzer\")\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"cxllin/Llama2-7b-Finance\"\n",
    "MAX_LENGTH = 512\n",
    "TEMPERATURE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data models\n",
    "class Article(BaseModel):\n",
    "    id: str\n",
    "    title: str\n",
    "    content: str\n",
    "    source: str\n",
    "    timestamp: str\n",
    "\n",
    "class Analysis(BaseModel):\n",
    "    article_id: str\n",
    "    timestamp: str\n",
    "    analysis: str\n",
    "    model: str\n",
    "    version: str\n",
    "    inference_time: Optional[float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "print(\"Loading model and tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float32,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(article: Article) -> str:\n",
    "    \"\"\"Create analysis prompt from article\"\"\"\n",
    "    return f\"\"\"Analyze this financial article briefly:\n",
    "\n",
    "Title: {article.title}\n",
    "Source: {article.source}\n",
    "Content: {article.content}\n",
    "\n",
    "Provide a concise analysis:\n",
    "1. Summary: Key points in 2-3 sentences\n",
    "2. Market Impact: Main effects on markets\n",
    "3. Trading Ideas: 1-2 specific trading opportunities\n",
    "4. Assets: Key instruments mentioned\n",
    "5. Risk: Low/Medium/High with brief reason\n",
    "\n",
    "Keep responses short and focused.\"\"\"\n",
    "\n",
    "@app.post(\"/analyze\", response_model=Analysis)\n",
    "async def analyze_article(article: Article):\n",
    "    \"\"\"Analyze a financial article\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Validate input\n",
    "        if not article.content:\n",
    "            raise HTTPException(status_code=400, detail=\"Article content is empty\")\n",
    "            \n",
    "        # Create prompt\n",
    "        prompt = create_prompt(article)\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH)\n",
    "        \n",
    "        # Generate analysis\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_new_tokens=MAX_LENGTH,\n",
    "                temperature=TEMPERATURE,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # Decode output\n",
    "        analysis = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Calculate time\n",
    "        inference_time = time.time() - start_time\n",
    "        \n",
    "        return Analysis(\n",
    "            article_id=article.id,\n",
    "            timestamp=article.timestamp,\n",
    "            analysis=analysis,\n",
    "            model=MODEL_NAME,\n",
    "            version=\"1.0\",\n",
    "            inference_time=inference_time\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the server\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
